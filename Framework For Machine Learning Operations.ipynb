{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framework for Building Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The generic MLOps workflow brings together Data Engineering, DevOps and Machine Learning\n",
    "- It is generally composed of the MLOps pipeline and drivers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *MLOps Pipeline*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The MLOps pipeline performs operations including building, deploying and monitoring models.\n",
    "- All models trained, deployed, and\n",
    "monitored using the MLOps method are end-to-end traceable and their lineage is logged in\n",
    "order to trace the origins of the model, which includes the source code the model used to\n",
    "train, the data used to train and test the model, and parameters used to converge the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Drivers*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The key drivers for the MLOps pipeline include data, code, artifacts, middleware and infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data**\n",
    "- To manage data in ML applications, data is handled in these steps: data acquisition, data annotation, data cataloging, data preparation, data quality checking, data sampling, and data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code**\n",
    "- There are three essential modules of code that drive the MLOps pipeline:\n",
    "training code, testing code, and application code. \n",
    "- These scripts or code are executed using the CI/CD and data pipelines to ensure the robust working of the MLOps pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Artifacts**\n",
    "- The MLOps pipeline generates artifacts such as data, serialized models,\n",
    "code snippets, system logs, ML model training, and testing metrics information. \n",
    "- All these artifacts are useful for the successful working of the MLOps pipeline, ensuring its traceability and sustainability. \n",
    "- These artifacts are managed using middleware services such as the model registry, workspaces, logging services, source code management services, databases, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Middleware**\n",
    "- Middleware refers to computer software that provides services to software applications that are more than those available from the OS.\n",
    "- Middleware services ensure multiple applications to automate and orchestrate\n",
    "processes for the MLOps pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Infrastructure**\n",
    "- Infrastructure essentially reers to storage and computing resources to ensure the successful working of the MLOps pipeline.\n",
    "- When it comes to the infrastructure, there are various options such as on-premises resources or infrastructure as a service (IaaS), which is cloud\n",
    "services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A fully automated MLOps workflow can be achieved through the ptimization and synergy of the drivers with the MLOps pipeline.\n",
    "- An advantage of having an automated MLOps workflow is the increase in the efficiency of the IT team by reducing the time spent working on repeatable tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characterizing you Machine Learning Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning solution development process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While ML offers many possibilities to augment and automate business, in order to get the best out of ML teams involved in ML-driven buisness transformation it is important to understand both ML and the business itself, including aspects such as value-chain analyis, use-case identification and business simulations to validate transformation.\n",
    "- Understanding the business is the first step of ML solutions, followed by data analysis where data is acquired, versioned and stores, after which it is consumed for ML modeling using data pipelines where feature engineering is done to get the right features to train the model. \n",
    "We evaluate the trained models and package them for deployment. Deployment and monitoring are done using a pipeline taking advantage of Continuous Integration/Continuous Deployment\n",
    "(CI/CD) features that enable real-time and continuous deployment to serve trained ML\n",
    "models to the users. \n",
    "- This process ensures robust and scalable ML solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Learning Models*\n",
    "- Supervised learning\n",
    "- Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hybrid models*\n",
    "- Semi-supervised learning(some data is labled and large amounts of data are unlabeled)\n",
    "- Self supervised learning(different from unsupervised learning in that it does not focus on clustering and grouping)\n",
    "- Multi-instance learning(supervised learning where data is not labeled by individual samples but rather in categories and samples)\n",
    "- Multitask learning(model trained on one dataset then used to solve multiple tasks, eg using word embeddins in NLP)\n",
    "- Reinforcement learning(an agent, such as a robot system, learns to operate in a defined environment to perform sequential decision-making tasks or achieve a pre-defined goal. Simultaneously, the agent learns based on continuously evaluated feedback and rewards from the environment.)\n",
    "- Ensemble learning(Two or more models trained on the same data and the result is the average of the outputs of the various models used to determine the final prediction)\n",
    "- Transfer learning(model is trained to perform a task, nd is transfered to another model to act as a starting point for finetuning or trainin for performing another task, eg, pretrained model like BERT models)\n",
    "- Federated learning(ML done is a collaborative fashion, training process distributed accross devices and data isn't shared for privacy and security)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Statistical models*\n",
    "- Inducive learning(It involves\n",
    "a process of learning by example, where a system tries to generalize a general function or rule from a set of observed instances. For example, when we fit an ML model, it is a process of induction.)\n",
    "- Deductive learning\n",
    "- Transductive learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bcd2c53e9736f599d911168c349fa93ea4da0fc59fb270cea2da0241c3d0904b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
